{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cnn_model import CNNModel\n",
    "from vit_model import ViTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll see if needed\n",
    "# Define transforms to preprocess the data (you can customize these as needed)\n",
    "TARGET_WIDTH = 224\n",
    "TARGET_HEIGHT = 224\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),              # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize the image\n",
    "    #transforms.Pad((111, 96, 112, 96), fill=0),  # Add Padding:  Our images are 64x33 (left,right,top, bottom)\n",
    "    transforms.Pad((95,80, 96, 80), fill=0) # Add padding for ViT (target is 224*224)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'holo': 0, 'non-holo': 1},\n",
       " {'holo': 0, 'non-holo': 1},\n",
       " {'holo': 0, 'non-holo': 1})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset using ImageFolder\n",
    "train_dataset = datasets.ImageFolder(root=\"dataset/train\", transform=transform)\n",
    "validation_dataset = datasets.ImageFolder(root=\"dataset/validation\", transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=\"dataset/test\", transform=transform)\n",
    "train_dataset.class_to_idx, validation_dataset.class_to_idx, test_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36000, 4500, 4500)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(validation_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label : holo\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 0\n",
    "plt.imshow(train_dataset[image_index][0].permute(1, 2, 0))\n",
    "print(f\"label : {train_dataset.classes[train_dataset[image_index][1]]}\")\n",
    "#Normalization will cause the colors to be off or to be impossible to read by imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DataLoader for each split using the respective sampler\n",
    "training_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True )\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = CNNModel(num_classes=1,\n",
    "#                 lr=0.0001)\n",
    "model = ViTModel(num_classes=1,\n",
    "                 lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNModel(\n",
       "  (pretrained_mobilenet): MobileNetV3(\n",
       "    (conv_stem): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNormAct2d(\n",
       "      16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "      (drop): Identity()\n",
       "      (act): Hardswish()\n",
       "    )\n",
       "    (blocks): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): DepthwiseSeparableConv(\n",
       "          (conv_dw): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pw): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(8, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(40, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(16, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=56, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(56, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=64, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(72, 72, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=72, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(72, 72, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=72, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): ConvBnAct(\n",
       "          (conv): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "    (conv_head): Conv2d(288, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (act2): Hardswish()\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (classifier): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  )\n",
       "  (accuracy_metric): BinaryAccuracy()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=\"models\",\n",
    "        monitor=\"validation_accuracy\",\n",
    "        filename=\"best\",\n",
    "        mode=\"max\",\n",
    "        save_last=True,\n",
    "        verbose=True\n",
    "    )\n",
    "# train the model\n",
    "trainer = L.Trainer(max_epochs=10,\n",
    "                    log_every_n_steps=1,\n",
    "                    val_check_interval=0.25,\n",
    "                    callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/yanis/paris_cite/S2/TER/model_training/venv/lib/python3.12/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:653: Checkpoint directory /home/yanis/paris_cite/S2/TER/model_training/models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                 | Type           | Params\n",
      "--------------------------------------------------------\n",
      "0 | pretrained_mobilenet | MobileNetV3    | 569 K \n",
      "1 | accuracy_metric      | BinaryAccuracy | 0     \n",
      "--------------------------------------------------------\n",
      "569 K     Trainable params\n",
      "0         Non-trainable params\n",
      "569 K     Total params\n",
      "2.277     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanis/paris_cite/S2/TER/model_training/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:492: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/home/yanis/paris_cite/S2/TER/model_training/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/yanis/paris_cite/S2/TER/model_training/venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanis/paris_cite/S2/TER/model_training/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  25%|██▍       | 70/282 [00:19<00:59,  3.56it/s, v_num=1, train_accuracy_step=0.711, validation_loss=0.673, validation_accuracy=0.598]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 70: 'validation_accuracy' reached 0.59844 (best 0.59844), saving model to '/home/yanis/paris_cite/S2/TER/model_training/models/best-v1.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|████▉     | 140/282 [00:37<00:38,  3.70it/s, v_num=1, train_accuracy_step=0.633, validation_loss=0.654, validation_accuracy=0.622]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 140: 'validation_accuracy' reached 0.62222 (best 0.62222), saving model to '/home/yanis/paris_cite/S2/TER/model_training/models/best-v1.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  74%|███████▍  | 210/282 [00:55<00:19,  3.77it/s, v_num=1, train_accuracy_step=0.656, validation_loss=0.642, validation_accuracy=0.628]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 210: 'validation_accuracy' reached 0.62800 (best 0.62800), saving model to '/home/yanis/paris_cite/S2/TER/model_training/models/best-v1.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  99%|█████████▉| 280/282 [01:13<00:00,  3.80it/s, v_num=1, train_accuracy_step=0.672, validation_loss=0.661, validation_accuracy=0.594]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 280: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  25%|██▍       | 70/282 [00:13<00:41,  5.05it/s, v_num=1, train_accuracy_step=0.672, validation_loss=0.661, validation_accuracy=0.610, train_accuracy_epoch=0.615] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 352: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|████▉     | 140/282 [00:26<00:27,  5.19it/s, v_num=1, train_accuracy_step=0.742, validation_loss=0.720, validation_accuracy=0.554, train_accuracy_epoch=0.615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 422: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  74%|███████▍  | 210/282 [00:40<00:13,  5.17it/s, v_num=1, train_accuracy_step=0.711, validation_loss=0.615, validation_accuracy=0.650, train_accuracy_epoch=0.615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 492: 'validation_accuracy' reached 0.64978 (best 0.64978), saving model to '/home/yanis/paris_cite/S2/TER/model_training/models/best-v1.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  99%|█████████▉| 280/282 [00:54<00:00,  5.18it/s, v_num=1, train_accuracy_step=0.617, validation_loss=0.610, validation_accuracy=0.670, train_accuracy_epoch=0.615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 562: 'validation_accuracy' reached 0.66978 (best 0.66978), saving model to '/home/yanis/paris_cite/S2/TER/model_training/models/best-v1.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  25%|██▍       | 70/282 [00:13<00:40,  5.22it/s, v_num=1, train_accuracy_step=0.672, validation_loss=0.599, validation_accuracy=0.664, train_accuracy_epoch=0.669] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 634: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  50%|████▉     | 140/282 [00:27<00:27,  5.18it/s, v_num=1, train_accuracy_step=0.742, validation_loss=0.647, validation_accuracy=0.637, train_accuracy_epoch=0.669]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 704: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  74%|███████▍  | 210/282 [00:40<00:13,  5.24it/s, v_num=1, train_accuracy_step=0.672, validation_loss=0.646, validation_accuracy=0.642, train_accuracy_epoch=0.669]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 774: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  99%|█████████▉| 280/282 [00:53<00:00,  5.22it/s, v_num=1, train_accuracy_step=0.695, validation_loss=0.597, validation_accuracy=0.671, train_accuracy_epoch=0.669]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 844: 'validation_accuracy' reached 0.67111 (best 0.67111), saving model to '/home/yanis/paris_cite/S2/TER/model_training/models/best-v1.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  25%|██▍       | 70/282 [00:15<00:46,  4.55it/s, v_num=1, train_accuracy_step=0.648, validation_loss=0.689, validation_accuracy=0.603, train_accuracy_epoch=0.686] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 916: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  50%|████▉     | 140/282 [00:32<00:32,  4.31it/s, v_num=1, train_accuracy_step=0.688, validation_loss=0.598, validation_accuracy=0.674, train_accuracy_epoch=0.686]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 986: 'validation_accuracy' reached 0.67356 (best 0.67356), saving model to '/home/yanis/paris_cite/S2/TER/model_training/models/best-v1.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  74%|███████▍  | 210/282 [00:47<00:16,  4.46it/s, v_num=1, train_accuracy_step=0.758, validation_loss=0.777, validation_accuracy=0.538, train_accuracy_epoch=0.686]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 1056: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  99%|█████████▉| 280/282 [01:00<00:00,  4.63it/s, v_num=1, train_accuracy_step=0.633, validation_loss=0.685, validation_accuracy=0.609, train_accuracy_epoch=0.686]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 1126: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  25%|██▍       | 70/282 [00:13<00:40,  5.17it/s, v_num=1, train_accuracy_step=0.703, validation_loss=0.725, validation_accuracy=0.578, train_accuracy_epoch=0.698] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 1198: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  50%|████▉     | 140/282 [00:26<00:27,  5.21it/s, v_num=1, train_accuracy_step=0.750, validation_loss=0.752, validation_accuracy=0.567, train_accuracy_epoch=0.698]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 1268: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  74%|███████▍  | 210/282 [00:40<00:13,  5.24it/s, v_num=1, train_accuracy_step=0.648, validation_loss=0.769, validation_accuracy=0.549, train_accuracy_epoch=0.698]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 1338: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  99%|█████████▉| 280/282 [00:53<00:00,  5.19it/s, v_num=1, train_accuracy_step=0.672, validation_loss=0.764, validation_accuracy=0.558, train_accuracy_epoch=0.698]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 1408: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  25%|██▍       | 70/282 [00:13<00:40,  5.22it/s, v_num=1, train_accuracy_step=0.750, validation_loss=0.592, validation_accuracy=0.684, train_accuracy_epoch=0.709] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 1480: 'validation_accuracy' reached 0.68378 (best 0.68378), saving model to '/home/yanis/paris_cite/S2/TER/model_training/models/best-v1.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  50%|████▉     | 140/282 [00:27<00:27,  5.16it/s, v_num=1, train_accuracy_step=0.688, validation_loss=0.672, validation_accuracy=0.624, train_accuracy_epoch=0.709]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 1550: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  74%|███████▍  | 210/282 [00:40<00:13,  5.20it/s, v_num=1, train_accuracy_step=0.781, validation_loss=0.726, validation_accuracy=0.595, train_accuracy_epoch=0.709]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 1620: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  99%|█████████▉| 280/282 [00:54<00:00,  5.18it/s, v_num=1, train_accuracy_step=0.742, validation_loss=0.615, validation_accuracy=0.672, train_accuracy_epoch=0.709]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 1690: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  25%|██▍       | 70/282 [00:13<00:40,  5.18it/s, v_num=1, train_accuracy_step=0.734, validation_loss=0.771, validation_accuracy=0.566, train_accuracy_epoch=0.713] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 1762: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  50%|████▉     | 140/282 [00:27<00:27,  5.10it/s, v_num=1, train_accuracy_step=0.727, validation_loss=0.590, validation_accuracy=0.687, train_accuracy_epoch=0.713]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 1832: 'validation_accuracy' reached 0.68733 (best 0.68733), saving model to '/home/yanis/paris_cite/S2/TER/model_training/models/best-v1.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  74%|███████▍  | 210/282 [00:41<00:14,  5.04it/s, v_num=1, train_accuracy_step=0.703, validation_loss=0.748, validation_accuracy=0.544, train_accuracy_epoch=0.713]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 1902: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  99%|█████████▉| 280/282 [00:55<00:00,  5.08it/s, v_num=1, train_accuracy_step=0.766, validation_loss=0.806, validation_accuracy=0.560, train_accuracy_epoch=0.713]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 1972: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  25%|██▍       | 70/282 [00:13<00:40,  5.20it/s, v_num=1, train_accuracy_step=0.703, validation_loss=0.598, validation_accuracy=0.681, train_accuracy_epoch=0.720] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 2044: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  50%|████▉     | 140/282 [00:27<00:27,  5.18it/s, v_num=1, train_accuracy_step=0.711, validation_loss=0.584, validation_accuracy=0.696, train_accuracy_epoch=0.720]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 2114: 'validation_accuracy' reached 0.69622 (best 0.69622), saving model to '/home/yanis/paris_cite/S2/TER/model_training/models/best-v1.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  74%|███████▍  | 210/282 [00:40<00:14,  5.13it/s, v_num=1, train_accuracy_step=0.781, validation_loss=0.601, validation_accuracy=0.678, train_accuracy_epoch=0.720]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 2184: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  99%|█████████▉| 280/282 [00:54<00:00,  5.16it/s, v_num=1, train_accuracy_step=0.727, validation_loss=0.707, validation_accuracy=0.620, train_accuracy_epoch=0.720]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 2254: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  25%|██▍       | 70/282 [00:13<00:40,  5.29it/s, v_num=1, train_accuracy_step=0.766, validation_loss=0.658, validation_accuracy=0.639, train_accuracy_epoch=0.724] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 2326: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  50%|████▉     | 140/282 [00:27<00:27,  5.18it/s, v_num=1, train_accuracy_step=0.797, validation_loss=0.805, validation_accuracy=0.573, train_accuracy_epoch=0.724]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 2396: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  74%|███████▍  | 210/282 [00:40<00:14,  5.14it/s, v_num=1, train_accuracy_step=0.750, validation_loss=0.691, validation_accuracy=0.615, train_accuracy_epoch=0.724]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 2466: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  99%|█████████▉| 280/282 [00:54<00:00,  5.13it/s, v_num=1, train_accuracy_step=0.766, validation_loss=0.592, validation_accuracy=0.688, train_accuracy_epoch=0.724]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 2536: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  25%|██▍       | 70/282 [00:13<00:41,  5.05it/s, v_num=1, train_accuracy_step=0.742, validation_loss=0.757, validation_accuracy=0.598, train_accuracy_epoch=0.732] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 2608: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  50%|████▉     | 140/282 [00:27<00:28,  5.01it/s, v_num=1, train_accuracy_step=0.742, validation_loss=0.695, validation_accuracy=0.642, train_accuracy_epoch=0.732]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 2678: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  74%|███████▍  | 210/282 [00:41<00:14,  5.02it/s, v_num=1, train_accuracy_step=0.695, validation_loss=0.580, validation_accuracy=0.693, train_accuracy_epoch=0.732]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 2748: 'validation_accuracy' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  99%|█████████▉| 280/282 [00:55<00:00,  5.02it/s, v_num=1, train_accuracy_step=0.727, validation_loss=0.582, validation_accuracy=0.697, train_accuracy_epoch=0.732]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 2818: 'validation_accuracy' reached 0.69733 (best 0.69733), saving model to '/home/yanis/paris_cite/S2/TER/model_training/models/best-v1.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 282/282 [00:56<00:00,  5.03it/s, v_num=1, train_accuracy_step=0.625, validation_loss=0.582, validation_accuracy=0.697, train_accuracy_epoch=0.738]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 282/282 [00:56<00:00,  5.02it/s, v_num=1, train_accuracy_step=0.625, validation_loss=0.582, validation_accuracy=0.697, train_accuracy_epoch=0.738]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=model, train_dataloaders=training_dataloader, val_dataloaders=validation_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"Loading model best.ckpt\")\n",
    "#best_model = CNNModel.load_from_checkpoint(\"models/best.ckpt\", num_classes=1, lr=0.0001).to('cuda')\n",
    "#best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model best.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNNModel(\n",
       "  (pretrained_mobilenet): MobileNetV3(\n",
       "    (conv_stem): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNormAct2d(\n",
       "      16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "      (drop): Identity()\n",
       "      (act): Hardswish()\n",
       "    )\n",
       "    (blocks): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): DepthwiseSeparableConv(\n",
       "          (conv_dw): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pw): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(8, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(40, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(16, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=56, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(56, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=64, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(72, 72, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=72, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(72, 72, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=72, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): ConvBnAct(\n",
       "          (conv): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "    (conv_head): Conv2d(288, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (act2): Hardswish()\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (classifier): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  )\n",
       "  (accuracy_metric): BinaryAccuracy()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Loading model best.ckpt\")\n",
    "best_model = ViTModel.load_from_checkpoint(\"models/best-ViT.ckpt\", num_classes=1, lr=0.0001).to('cuda')\n",
    "#best_model = CNNModel.load_from_checkpoint(\"models/best-CNN.ckpt\", num_classes=1, lr=0.0001).to('cuda')\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanis/paris_cite/S2/TER/model_training/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:492: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/home/yanis/paris_cite/S2/TER/model_training/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 36/36 [00:05<00:00,  7.03it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.6966666579246521\n",
      "        test_loss           0.5684449076652527\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.5684449076652527, 'test_accuracy': 0.6966666579246521}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=best_model, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, label = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 224, 224])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = input.to('cuda')\n",
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = label.to('cuda')\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every INPUT_SIZE / Prediction size do the prediction then append\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "        #input = input.unsqueeze(0).to('cpu')\n",
    "        #print(input)\n",
    "        y_hat = best_model(input).squeeze()\n",
    "        result = torch.nn.functional.sigmoid(y_hat)\n",
    "# Output the last 100 of the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9351, 0.9714, 0.3627, 0.1418, 0.5261, 0.9647, 0.6980, 0.4075, 0.7207,\n",
       "        0.5179, 0.0435, 0.5058, 0.0073, 0.9472, 0.8690, 0.5513, 0.9751, 0.9591,\n",
       "        0.6555, 0.8751, 0.8892, 0.6918, 0.4900, 0.0498, 0.7538, 0.9683, 0.6867,\n",
       "        0.9061, 0.9249, 0.9157, 0.1855, 0.7719, 0.9694, 0.7420, 0.9255, 0.0397,\n",
       "        0.7750, 0.8253, 0.6235, 0.6668, 0.6615, 0.2057, 0.2617, 0.0080, 0.8687,\n",
       "        0.9533, 0.3209, 0.0161, 0.0356, 0.0656, 0.9721, 0.9669, 0.2779, 0.8716,\n",
       "        0.9646, 0.3607, 0.9113, 0.9637, 0.9039, 0.7049, 0.5602, 0.6361, 0.0273,\n",
       "        0.9400, 0.2535, 0.7930, 0.0390, 0.8970, 0.9526, 0.9416, 0.4072, 0.0072,\n",
       "        0.0093, 0.3741, 0.9503, 0.3566, 0.8670, 0.3487, 0.1036, 0.4163, 0.9888,\n",
       "        0.9069, 0.7401, 0.0678, 0.9539, 0.4978, 0.8160, 0.9348, 0.8016, 0.9649,\n",
       "        0.9311, 0.2102, 0.9488, 0.0719, 0.9170, 0.8647, 0.8692, 0.5067, 0.3115,\n",
       "        0.0758, 0.9592, 0.4297, 0.9075, 0.0162, 0.2135, 0.7954, 0.1990, 0.0786,\n",
       "        0.0626, 0.7620, 0.0085, 0.0726, 0.4273, 0.4229, 0.9776, 0.0235, 0.0712,\n",
       "        0.9103, 0.9200, 0.9606, 0.8916, 0.8375, 0.2391, 0.9080, 0.1865, 0.9112,\n",
       "        0.8205, 0.0308], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "        0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "        1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "        1, 0, 0, 1, 0, 1, 1, 0], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
