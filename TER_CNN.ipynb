{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUsJeAsZ3kUA"
      },
      "source": [
        "This is for implementing CNN in order to determine if string contains hologram or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "11CuVoXL3wUp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "import os\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crJWnUzna6Fu"
      },
      "source": [
        "Upload our data from google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3HiRZzSa-LO",
        "outputId": "280dd8a5-bb3c-4c6b-d855-d861720bd36b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_VfpYESJbUr5"
      },
      "outputs": [],
      "source": [
        "# Specify the path to the ZIP file\n",
        "zip_file_path = \"/content/gdrive/MyDrive/MASTER/TER/generatedImages.zip\"\n",
        "\n",
        "# Extract the contents of the ZIP file to a specified directory\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zipped_data:\n",
        "    zipped_data.extractall(\"/temp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2DGwuTXcoujb"
      },
      "outputs": [],
      "source": [
        "# we'll see if needed\n",
        "# Define transforms to preprocess the data (you can customize these as needed)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Pad((180, 0, 211, 0), fill=0),  # Add Padding:  Our images are 64x33 (left,right,top, bottom)\n",
        "     transforms.Resize((244, 244)),\n",
        "    #transforms.CenterCrop(224),         # Crop the center 224x224 portion of the image\n",
        "    transforms.ToTensor(),              # Convert the image to a PyTorch tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "D-GyMTY7pHcE"
      },
      "outputs": [],
      "source": [
        "# Load the dataset using ImageFolder\n",
        "dataset = datasets.ImageFolder(root=\"/temp\", transform=transform)\n",
        "\n",
        "# The size for each data split\n",
        "train_size = int(0.001*len(dataset))\n",
        "validation_size = int(0.899*len(dataset))\n",
        "test_size = int(0.1*len(dataset))\n",
        "\n",
        "# Use random_split to split the dataset into train, validation, and test sets\n",
        "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, validation_size, test_size])\n",
        "\n",
        "\n",
        "# Define DataLoader for each split using the respective sampler\n",
        "training = DataLoader(train_dataset, batch_size=128, shuffle=True )\n",
        "validation = DataLoader(val_dataset, batch_size=128, shuffle=True)\n",
        "testing = DataLoader(test_dataset, batch_size=128, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_S7rQOMkD0hu"
      },
      "outputs": [],
      "source": [
        "# Define your CNN architecture\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.fc1 = nn.Linear(64*61*61, 128)\n",
        "        self.fc2 = nn.Linear(128, 2)  # Output 2 classes: 0 or 1\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3z1cje8vEBTp",
        "outputId": "74801efe-3363-4fd5-d735-d30a274efd12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 0.6886025071144104\n",
            "Epoch 2/10, Loss: 9.388144493103027\n",
            "Epoch 3/10, Loss: 22.148944854736328\n",
            "Epoch 4/10, Loss: 9.159502029418945\n",
            "Epoch 5/10, Loss: 0.5240204930305481\n",
            "Epoch 6/10, Loss: 2.5209641456604004\n",
            "Epoch 7/10, Loss: 1.9644497632980347\n",
            "Epoch 8/10, Loss: 1.0095784664154053\n",
            "Epoch 9/10, Loss: 0.5593355298042297\n",
            "Epoch 10/10, Loss: 0.6702460050582886\n",
            "Accuracy: 48.833333333333336%\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the CNN model\n",
        "model = CNN()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in training:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(training)}\")\n",
        "\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testing:\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy: {100 * correct / total}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
